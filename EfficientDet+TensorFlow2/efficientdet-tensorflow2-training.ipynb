{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Installations"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tf_slim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pycocotools\n!pip install lvis\n!pip install numba ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Download and extract TensorFlow Model Garden or cd to it if it exists"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pathlib\n\nif \"models\" in pathlib.Path.cwd().parts:\n    while \"models\" in pathlib.Path.cwd().parts:\n        os.chdir('..')\nelif not pathlib.Path('models').exists():\n    !git clone --depth 1 https://github.com/tensorflow/models","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compile Protobufs and Install the Object Detection Package"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\ncd models/research/\nprotoc object_detection/protos/*.proto --python_out=.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%bash \n# cd models/research\n# pip install .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash \ncd models/research\ncp object_detection/packages/tf2/setup.py .\npython -m pip install .","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set Environment Variabes"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.environ['PYTHONPATH'] += \":/kaggle/working/models\"\n\nimport sys\nsys.path.append(\"/kaggle/working/models\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import Packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport os\nimport sys\nimport tarfile\nimport tensorflow as tf\nimport zipfile\nimport cv2\nimport json\nimport pandas as pd\nimport glob\nimport os.path as osp\nfrom path import Path\nimport datetime\nimport random\nimport shutil\nfrom io import StringIO, BytesIO\nfrom PIL import Image\nfrom IPython.display import display\nimport re\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import rcParams\nsns.set(rc={\"font.size\":9,\"axes.titlesize\":15,\"axes.labelsize\":9,\n            \"axes.titlepad\":11, \"axes.labelpad\":9, \"legend.fontsize\":7,\n            \"legend.title_fontsize\":7, 'axes.grid' : False})\n\nfrom sklearn.model_selection import train_test_split\n\n## Import object detection module\nfrom object_detection.utils import ops as utils_ops\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import visualization_utils as vis_utils\nfrom object_detection.protos.string_int_label_map_pb2 import StringIntLabelMap, StringIntLabelMapItem\nfrom object_detection.utils import config_util\nfrom object_detection.builders import model_builder\n\nfrom google.protobuf import text_format\n\nimport tarfile\nfrom numba import cuda ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Patches"},{"metadata":{"trusted":true},"cell_type":"code","source":"# patch tf1 into `utils.ops`\nutils_ops.tf = tf.compat.v1\n\n# Patch the location of gfile\ntf.gfile = tf.io.gfile","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load and Infer Using a Pre-trained Model\n"},{"metadata":{},"cell_type":"markdown","source":"## Loading Label Map"},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\ncategory_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Download Model Files"},{"metadata":{"trusted":true},"cell_type":"code","source":"pretrained_dir = \"/kaggle/working/training_job/model/\"\n\nif not os.path.exists(pretrained_dir):\n    os.makedirs(pretrained_dir)\n    print('Pretrainined Model Directory:', pretrained_dir)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Choosing Pre-trained Model & Downloading Weight Files\n- https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md"},{"metadata":{"trusted":true},"cell_type":"code","source":"## EfficientDet Configurations\n\nMODELS_CONFIG = {\n    'efficientdet-d0': {\n        'model_name': 'efficientdet_d0_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n    },\n    'efficientdet-d1': {\n        'model_name': 'efficientdet_d1_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n    },\n    'efficientdet-d2': {\n        'model_name': 'efficientdet_d2_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n    },\n    'efficientdet-d3': {\n        'model_name': 'efficientdet_d3_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n    },\n    'efficientdet-d4': {\n        'model_name': 'efficientdet_d4_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d4_896x896_coco17_tpu-32.config',\n        'pretrained_checkpoint': 'efficientdet_d4_coco17_tpu-32.tar.gz',\n    },\n    'efficientdet-d5': {\n        'model_name': 'efficientdet_d5_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d5_896x896_coco17_tpu-32.config',\n        'pretrained_checkpoint': 'efficientdet_d5_coco17_tpu-32.tar.gz',\n    },\n    'efficientdet-d6': {\n        'model_name': 'efficientdet_d6_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d6_896x896_coco17_tpu-32.config',\n        'pretrained_checkpoint': 'efficientdet_d6_coco17_tpu-32.tar.gz',\n    },\n    'efficientdet-d7': {\n        'model_name': 'efficientdet_d7_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d7_896x896_coco17_tpu-32.config',\n        'pretrained_checkpoint': 'efficientdet_d7_coco17_tpu-32.tar.gz',\n    }\n}\n\n## Choosing D1 here for this tutorial\nchosen_model = 'efficientdet-d1'\nmodel_name = MODELS_CONFIG[chosen_model]['model_name']\npretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\nbase_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/'+pretrained_checkpoint\n# pretrained_dir = \"/kaggle/working/models/research/object_detection/pretrained\"\n\n!wget {model_url}\n!tar -xf {pretrained_checkpoint}\n!mv {model_name}/ {pretrained_dir}\n!rm {pretrained_checkpoint}\n\nmodel_dir = os.path.join(pretrained_dir, model_name, \"saved_model\")\nprint(\"Pre-trained model directory\", model_dir)\nmodel = tf.saved_model.load(str(model_dir))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Display the Output Structure"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.signatures['serving_default'].output_dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.signatures['serving_default'].output_shapes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_inference_for_single_image(model, image):\n    '''\n    Add a wrapper function to call the model, and cleanup the outputs:\n    '''\n    image = np.asarray(image)\n    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n    input_tensor = tf.convert_to_tensor(image)\n    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n    input_tensor = input_tensor[tf.newaxis,...]\n\n    # Run inference\n    model_fn = model.signatures['serving_default']\n    output_dict = model_fn(input_tensor)\n\n    # All outputs are batches tensors.\n    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n    # We're only interested in the first num_detections.\n    num_detections = int(output_dict.pop('num_detections'))\n    output_dict = {key:value[0, :num_detections].numpy() for key,value in output_dict.items()}\n    output_dict['num_detections'] = num_detections\n\n    # detection_classes should be ints.\n    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n\n    # Handle models with masks:\n    if 'detection_masks' in output_dict:\n        # Reframe the the bbox mask to the image size.\n        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n                  output_dict['detection_masks'], output_dict['detection_boxes'],\n                   image.shape[0], image.shape[1])      \n        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n                                           tf.uint8)\n        output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n\n    return output_dict\n\ndef show_inference(model, image_path):\n    # the array based representation of the image will be used later in order to prepare the\n    # result image with boxes and labels on it.\n    image_np = np.array(Image.open(image_path))\n    # Actual detection.\n    output_dict = run_inference_for_single_image(model, image_np)\n    # Visualization of the results of a detection.\n    vis_utils.visualize_boxes_and_labels_on_image_array(\n      image_np,\n      output_dict['detection_boxes'],\n      output_dict['detection_classes'],\n      output_dict['detection_scores'],\n      category_index,\n      instance_masks=output_dict.get('detection_masks_reframed', None),\n      use_normalized_coordinates=True,\n      line_thickness=8)\n\n    return image_np\n    \ndef load_image_into_numpy_array(path):\n    \"\"\"Load an image from file into a numpy array.\n\n    Puts image into numpy array to feed into tensorflow graph.\n    Note that by convention we put it into a numpy array with shape\n    (height, width, channels), where channels=3 for RGB.\n\n    Args:\n    path: a file path.\n\n    Returns:\n    uint8 numpy array with shape (img_height, img_width, 3)\n    \"\"\"\n    img_data = tf.io.gfile.GFile(path, 'rb').read()\n    image = Image.open(BytesIO(img_data))\n    (im_width, im_height) = image.size\n    return np.array(image.getdata()).reshape(\n      (im_height, im_width, 3)).astype(np.uint8)\n\ndef plot_detections(image_np, boxes, classes, scores, category_index,\n                    figsize=(12, 16), image_name=None):\n    \"\"\"Wrapper function to visualize detections.\n\n    Args:\n    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n    boxes: a numpy array of shape [N, 4]\n    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n      and match the keys in the label map.\n    scores: a numpy array of shape [N] or None.  If scores=None, then\n      this function assumes that the boxes to be plotted are groundtruth\n      boxes and plot all boxes as black with no classes or scores.\n    category_index: a dict containing category dictionaries (each holding\n      category index `id` and category name `name`) keyed by category indices.\n    figsize: size for the figure.\n    image_name: a name for the image file.\n    \"\"\"\n    image_np_with_annotations = image_np.copy()\n    viz_utils.visualize_boxes_and_labels_on_image_array(\n      image_np_with_annotations,\n      boxes,\n      classes,\n      scores,\n      category_index,\n      use_normalized_coordinates=True,\n      min_score_thresh=0.8)\n    if image_name:\n        plt.imsave(image_name, image_np_with_annotations)\n    else:\n        plt.imshow(image_np_with_annotations)\n        \n        \ndef plot_img(img, size=(18, 18), is_rgb=True, title=\"\", cmap='gray'):\n    plt.figure(figsize=size)\n    plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Run the Model on Sample Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://cdn.pixabay.com/photo/2015/03/26/09/43/city-690158_960_720.jpg\n!wget https://cdn.pixabay.com/photo/2017/08/05/23/31/people-2586656_960_720.jpg\n!wget https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg\n    \n!wget https://cdn.pixabay.com/photo/2020/02/07/15/33/girl-4827500_960_720.jpg\nTEST_IMAGE_PATHS = [\n                    'girl-4827500_960_720.jpg',\n                    'Naxos_Taverna.jpg',\n                    'city-690158_960_720.jpg'\n                   ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image_path in TEST_IMAGE_PATHS:\n    image = show_inference(model, image_path)\n    os.remove(image_path)\n    plot_img(image)\n    plt.savefig('{}_viz.png'.format(image_path))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Delete Model and Release GPU Memory"},{"metadata":{"trusted":true},"cell_type":"code","source":"del model\ndevice = cuda.get_current_device()\ndevice.reset()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TFRecord Creation"},{"metadata":{},"cell_type":"markdown","source":"## Create Ouput TFRecord Folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfr_output_dir = \"/kaggle/working/training_job/tfrecords/\"\n\nif not os.path.exists(tfr_output_dir):\n    os.makedirs(tfr_output_dir)\n    print('TFRecord Directory:', tfr_output_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\npython models/research/object_detection/dataset_tools/create_coco_tf_record.py --logtostderr \\\n--train_image_dir=\"../input/vinbigdata-coco-dataset-with-wbf-3x-downscaled/vinbigdata-coco-dataset-with-wbf-3x-downscaled\" \\\n--test_image_dir=\"../input/vinbigdata-coco-dataset-with-wbf-3x-downscaled/vinbigdata-coco-dataset-with-wbf-3x-downscaled\" \\\n--val_image_dir=\"../input/vinbigdata-coco-dataset-with-wbf-3x-downscaled/vinbigdata-coco-dataset-with-wbf-3x-downscaled\" \\\n--train_annotations_file=\"../input/vinbigdata-coco-dataset-with-wbf-3x-downscaled/vinbigdata-coco-dataset-with-wbf-3x-downscaled/train_annotations.json\" \\\n--testdev_annotations_file=\"../input/vinbigdata-coco-dataset-with-wbf-3x-downscaled/vinbigdata-coco-dataset-with-wbf-3x-downscaled/val_annotations.json\" \\\n--val_annotations_file=\"../input/vinbigdata-coco-dataset-with-wbf-3x-downscaled/vinbigdata-coco-dataset-with-wbf-3x-downscaled/val_annotations.json\" \\\n--output_dir=\"/kaggle/working/training_job/tfrecords/\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the Label Map File"},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_classes(classes, start=1):\n    msg = StringIntLabelMap()\n    for id, name in enumerate(classes, start=start):\n        msg.item.append(StringIntLabelMapItem(id=id, name=name))\n    text = str(text_format.MessageToBytes(msg, as_utf8=True), 'utf-8')\n    return text\n\nlabels =  [\n            \"Aortic_enlargement\",\n            \"Atelectasis\",\n            \"Calcification\",\n            \"Cardiomegaly\",\n            \"Consolidation\",\n            \"ILD\",\n            \"Infiltration\",\n            \"Lung_Opacity\",\n            \"Nodule_Mass\",\n            \"Other_lesion\",\n            \"Pleural_effusion\",\n            \"Pleural_thickening\",\n            \"Pneumothorax\",\n            \"Pulmonary_fibrosis\"\n            ]\n\ntxt = convert_classes(labels)\nprint(txt)\nwith open('/kaggle/working/training_job/label_map.pbtxt', 'w') as f:\n    f.write(txt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing Train Job Folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_files_dir = \"/kaggle/working/training_job/model_files/\"\n\nif not os.path.exists(model_files_dir):\n    os.makedirs(model_files_dir)\n    print('Model Files Directory:', model_files_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Download pretrained weights\ndownload_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n!wget {download_tar} -P {model_files_dir}\ntar = tarfile.open(os.path.join(model_files_dir, pretrained_checkpoint))\ntar.extractall()\ntar.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Download base training configuration file\n\ndownload_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/'+base_pipeline_file\n!wget {download_config} -P {model_files_dir}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Get the Total Number of Classes\n\ndef get_num_classes(pbtxt_fname):\n    from object_detection.utils import label_map_util\n    label_map = label_map_util.load_labelmap(pbtxt_fname)\n    categories = label_map_util.convert_label_map_to_categories(\n        label_map, max_num_classes=90, use_display_name=True)\n    category_index = label_map_util.create_category_index(categories)\n    return len(category_index.keys())\n\n\nval_record_fname = '/kaggle/working/training_job/tfrecords/coco_val.record*'\ntrain_record_fname = '/kaggle/working/training_job/tfrecords/coco_train.record*'\nlabel_map_pbtxt_fname = '/kaggle/working/training_job/label_map.pbtxt'\n\npipeline_file = os.path.join(model_files_dir, base_pipeline_file)\nfine_tune_checkpoint = os.path.join(pretrained_dir, model_name, 'checkpoint/ckpt-0')\nnum_classes = get_num_classes(label_map_pbtxt_fname)\nprint(\"No. of Classes\", num_classes)\nprint(\"Checkpoint File Path\", fine_tune_checkpoint)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Configuring the Model Training Pipeline File"},{"metadata":{},"cell_type":"markdown","source":"## File Structure"},{"metadata":{"trusted":true},"cell_type":"code","source":"# SSD with EfficientNet-b1 + BiFPN feature extractor,\n# shared box predictor and focal loss (a.k.a EfficientDet-d1).\n# See EfficientDet, Tan et al, https://arxiv.org/abs/1911.09070\n# See Lin et al, https://arxiv.org/abs/1708.02002\n# Trained on COCO, initialized from an EfficientNet-b1 checkpoint.\n#\n# Train on TPU-8\n\n# model {\n#   ssd {\n#     inplace_batchnorm_update: true\n#     freeze_batchnorm: false\n#     num_classes: 90\n#     add_background_class: false\n#     box_coder {\n#       faster_rcnn_box_coder {\n#         y_scale: 10.0\n#         x_scale: 10.0\n#         height_scale: 5.0\n#         width_scale: 5.0\n#       }\n#     }\n#     matcher {\n#       argmax_matcher {\n#         matched_threshold: 0.5\n#         unmatched_threshold: 0.5\n#         ignore_thresholds: false\n#         negatives_lower_than_unmatched: true\n#         force_match_for_each_row: true\n#         use_matmul_gather: true\n#       }\n#     }\n#     similarity_calculator {\n#       iou_similarity {\n#       }\n#     }\n#     encode_background_as_zeros: true\n#     anchor_generator {\n#       multiscale_anchor_generator {\n#         min_level: 3\n#         max_level: 7\n#         anchor_scale: 4.0\n#         aspect_ratios: [1.0, 2.0, 0.5]\n#         scales_per_octave: 3\n#       }\n#     }\n#     image_resizer {\n#       keep_aspect_ratio_resizer {\n#         min_dimension: 640\n#         max_dimension: 640\n#         pad_to_max_dimension: true\n#         }\n#     }\n#     box_predictor {\n#       weight_shared_convolutional_box_predictor {\n#         depth: 88\n#         class_prediction_bias_init: -4.6\n#         conv_hyperparams {\n#           force_use_bias: true\n#           activation: SWISH\n#           regularizer {\n#             l2_regularizer {\n#               weight: 0.00004\n#             }\n#           }\n#           initializer {\n#             random_normal_initializer {\n#               stddev: 0.01\n#               mean: 0.0\n#             }\n#           }\n#           batch_norm {\n#             scale: true\n#             decay: 0.99\n#             epsilon: 0.001\n#           }\n#         }\n#         num_layers_before_predictor: 3\n#         kernel_size: 3\n#         use_depthwise: true\n#       }\n#     }\n#     feature_extractor {\n#       type: 'ssd_efficientnet-b1_bifpn_keras'\n#       bifpn {\n#         min_level: 3\n#         max_level: 7\n#         num_iterations: 4\n#         num_filters: 88\n#       }\n#       conv_hyperparams {\n#         force_use_bias: true\n#         activation: SWISH\n#         regularizer {\n#           l2_regularizer {\n#             weight: 0.00004\n#           }\n#         }\n#         initializer {\n#           truncated_normal_initializer {\n#             stddev: 0.03\n#             mean: 0.0\n#           }\n#         }\n#         batch_norm {\n#           scale: true,\n#           decay: 0.99,\n#           epsilon: 0.001,\n#         }\n#       }\n#     }\n#     loss {\n#       classification_loss {\n#         weighted_sigmoid_focal {\n#           alpha: 0.25\n#           gamma: 1.5\n#         }\n#       }\n#       localization_loss {\n#         weighted_smooth_l1 {\n#         }\n#       }\n#       classification_weight: 1.0\n#       localization_weight: 1.0\n#     }\n#     normalize_loss_by_num_matches: true\n#     normalize_loc_loss_by_codesize: true\n#     post_processing {\n#       batch_non_max_suppression {\n#         score_threshold: 1e-8\n#         iou_threshold: 0.5\n#         max_detections_per_class: 100\n#         max_total_detections: 100\n#       }\n#       score_converter: SIGMOID\n#     }\n#   }\n# }\n\n# train_config: {\n#   fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED/ckpt-0\"\n#   fine_tune_checkpoint_version: V2\n#   fine_tune_checkpoint_type: \"classification\"\n#   batch_size: 128\n#   sync_replicas: true\n#   startup_delay_steps: 0\n#   replicas_to_aggregate: 8\n#   use_bfloat16: true\n#   num_steps: 300000\n#   data_augmentation_options {\n#     random_horizontal_flip {\n#     }\n#   }\n#   data_augmentation_options {\n#     random_scale_crop_and_pad_to_square {\n#       output_size: 640\n#       scale_min: 0.1\n#       scale_max: 2.0\n#     }\n#   }\n#   optimizer {\n#     momentum_optimizer: {\n#       learning_rate: {\n#         cosine_decay_learning_rate {\n#           learning_rate_base: 8e-2\n#           total_steps: 300000\n#           warmup_learning_rate: .001\n#           warmup_steps: 2500\n#         }\n#       }\n#       momentum_optimizer_value: 0.9\n#     }\n#     use_moving_average: false\n#   }\n#   max_number_of_boxes: 100\n#   unpad_groundtruth_tensors: false\n# }\n\n# train_input_reader: {\n#   label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n#   tf_record_input_reader {\n#     input_path: \"PATH_TO_BE_CONFIGURED/train2017-?????-of-00256.tfrecord\"\n#   }\n# }\n\n# eval_config: {\n#   metrics_set: \"coco_detection_metrics\"\n#   use_moving_averages: false\n#   batch_size: 1;\n# }\n\n# eval_input_reader: {\n#   label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n#   shuffle: false\n#   num_epochs: 1\n#   tf_record_input_reader {\n#     input_path: \"PATH_TO_BE_CONFIGURED/val2017-?????-of-00032.tfrecord\"\n#   }\n# }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Train Images = 3296\n## 3296/8 = 412\n## Val Images = 1098\n## 1098/8 ~= 138\n\n## Training Configurations\nnum_epochs = 5\nnum_steps = 412*num_epochs\nnum_eval_steps = 138\nbatch_size = 8\nprint(\"Number of Steps:\", num_steps)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modify the Pipeline Configuration File"},{"metadata":{"trusted":true},"cell_type":"code","source":"#write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file\n\nprint('Updading the Training Configuration file')\nwith open(pipeline_file) as f:\n    s = f.read()\n    \nwith open(pipeline_file, 'w') as f:\n    \n    # fine_tune_checkpoint\n    s = re.sub('fine_tune_checkpoint: \".*?\"',\n               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n    \n    # tfrecord files train and test.\n    s = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")',\n               'input_path: \"{}\"'.format(train_record_fname), s)\n    \n    s = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")',\n               'input_path: \"{}\"'.format(val_record_fname), s)\n\n    # label_map_path\n    s = re.sub('label_map_path: \".*?\"',\n               'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n\n    # Set training batch_size.\n    s = re.sub('batch_size: [0-9]+',\n               'batch_size: {}'.format(batch_size), s)\n\n    # Set training steps, num_steps\n    s = re.sub('num_steps: [0-9]+',\n               'num_steps: {}'.format(num_steps), s)\n    \n    # Set number of classes num_classes.\n    s = re.sub('num_classes: [0-9]+',\n               'num_classes: {}'.format(num_classes), s)\n    \n    \n    #fine-tune checkpoint type\n    s = re.sub('fine_tune_checkpoint_type: \"classification\"',\n               'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n        \n    f.write(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!cat {pipeline_file}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Custom TF2 Object Detector"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_dir = \"/kaggle/working/training_job/model_files/training/\"\n\nif not os.path.exists(model_dir):\n    os.makedirs(model_dir)\n    print('Training Files:', model_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Checking GPU Load\n!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Start Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"!python /kaggle/working/models/research/object_detection/model_main_tf2.py \\\n    --pipeline_config_path={pipeline_file} \\\n    --model_dir={model_dir} \\\n    --alsologtostderr \\\n    --num_train_steps={num_steps} \\\n    --sample_1_of_n_eval_examples=1 \\\n    --num_eval_steps={num_eval_steps}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Evaluation"},{"metadata":{},"cell_type":"markdown","source":"## Perform Evaluation using Model Main"},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimport os\nos.environ['PYTHONPATH'] += \":/kaggle/working/models\"\nimport sys\nsys.path.append(\"/kaggle/working/models\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_dir = \"/kaggle/working/training_job/model_files/training/\"\npipeline_file = glob.glob(os.path.join('/kaggle/working/training_job/model_files/', '*.config'))[0]\npipeline_file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Stop this cell manually\n!python /kaggle/working/models/research/object_detection/model_main_tf2.py \\\n     --pipeline_config_path={pipeline_file} \\\n     --model_dir={model_dir} \\\n     --checkpoint_dir={model_dir} \\\n     --run_once=True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}